---
# title: "Transform"
# author: "Kasthuri Kannan"
# date: "Sept 07, 2017"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

---

### Data science fundamentals 02: Transform and explore  

---

We will work with RNA-seq data set. In the spirit of the data transformation section in R for Data Science, we will look into `dplyr()` functions. As usual, we will first import the RNA-seq data set in RStudio:

```{r eval=TRUE, message=FALSE}
  # Load the package RCurl
  library(RCurl)
  # Import the RNAseq data set from GitHub; break the string into two for readability
  # (Please note this readability aspect very carefully)
  URL_text_1 <- "https://raw.githubusercontent.com/kannan-kasthuri/kannan-kasthuri.github.io"
  URL_text_2 <- "/master/Workshops/DS_Transcriptomics/Data/marked_data_7000_genes.txt"
  # Paste it to constitute a single URL and import the data
  URL <- paste(URL_text_1,URL_text_2, sep="")
  imported.RNA.seq <- read.csv(text=getURL(URL), sep="\t", header = TRUE, stringsAsFactors = FALSE, row.names = 1)
  # Get the gene names
  gene.names <- row.names(imported.RNA.seq)
  # Append "Patiend ID (PID)" variable to make "our" data frame
  column.names <- append("PID",gene.names)
  # Get only the gene expression matrix
  expression <- as.numeric(t(imported.RNA.seq[c(2:6917),c(1:52)]))
  # Get the group values
  group <- t(imported.RNA.seq[1,])
```

We may want to convert the Ensembl gene names to official gene names. The package `org.Hs.eg.db` can help us here. First lets install this library.

```{r eval=TRUE, message=FALSE}
# Load the library
library(org.Hs.eg.db)
# Define ensemble gene ids
ensembl.names <- gene.names[c(2:6918)]
# Convert using the select function
my_official_ids <- select(org.Hs.eg.db,
                          keys = ensembl.names,
                          columns=c("ENSEMBL","SYMBOL"),
                          keytype="ENSEMBL")
# We add the ensemble id to the existing data set to merge with official symbols
imported.RNA.seq$ENSEMBL <- row.names(imported.RNA.seq)
merged.data <- merge(imported.RNA.seq,my_official_ids,by=c("ENSEMBL"), no.dups = 1, all = TRUE)
# Omit the NA rows in the merged data
merged.data <- na.omit(merged.data)
```

We will now make our own data frame with official gene names which we will use.

```{r eval=TRUE, message=FALSE}
# Make our data frame - note - merged data has 52 patients and 6678 genes
df <- data.frame(matrix(ncol = 6680, nrow = 52))
# The first column are the patient ids
df[,1] <- colnames(merged.data)[2:53]
# The next two columns are Patient ID (PID) and Group. The rest are official gene names
column.names <- append(c("PID","Group"),merged.data$SYMBOL)
colnames(df) <- column.names
# Assign the group information
df[,2] <- group[,1]
# The rest of the matrices are expression values
expression <- as.numeric(t(merged.data[c(1:6678),c(2:53)]))
df[c(1:52),c(3:6680)] <- expression
```

We can now use these official symbol for the rest of the analysis.

We will see more about tibbles later but we will make a short note of it now.

A tibble, or `tbl_df`, is a modern reimagining of the data frame, keeping what time has proven to be effective, and throwing out what is not. Tibbles are data.frames that are lazy and surly: they do less (i.e. they don’t change variable names or types, and don’t do partial matching) and complain more (e.g. when a variable does not exist). This forces one to confront problems earlier, typically leading to cleaner, more expressive code. Tibbles also have an enhanced `print method()` which makes them easier to use with large datasets containing complex objects.

To convert a data frame to a tibble, we can use the function `as.tibble(df)` where df is a data frame. We will convert the `df` data frame into tibble and use the tibble from now on.

```{r eval=FALSE, message=FALSE, warning=FALSE}
  # Load the tidyverse library
  library(tidyverse)
  # Convert df data frame into a tibble and observe it
  df_TIB <- as.tibble(df)
  df_TIB
```

Thus, we get an error. All `dplyr()` functions require unique names for the columns. We will see in the below tutorial how this situation can be handled differently. But first, we need to sort this out - 

```{r eval=TRUE, message=FALSE, warning=FALSE}
# Get only the unique values for the gene symbol
merged.data.unique <- merged.data[!duplicated(merged.data$SYMBOL),]
# Make our data frame - note - merged data has 52 patients and 6644 genes
df.uniq <- data.frame(matrix(ncol = 6646, nrow = 52))
# The first column are the patient ids
df.uniq[,1] <- colnames(merged.data)[2:53]
# The next two columns are Patient ID (PID) and Group. The rest are official gene names
column.names.uniq <- append(c("PID","Group"),merged.data.unique$SYMBOL)
colnames(df.uniq) <- column.names.uniq
# Assign the group information
df.uniq[,2] <- group[,1]
# The rest of the matrices are expression values
expression <- as.numeric(t(merged.data[c(1:6644),c(2:53)]))
df.uniq[c(1:52),c(3:6646)] <- expression
```

We can now see the tibble doesn't give any errors

```{r eval=TRUE, message=FALSE, warning=FALSE}
  # Load the tidyverse library
  library(tidyverse)
  # Convert df.uniq data frame into a tibble and observe it
  df_TIB <- as.tibble(df.uniq)
  df_TIB
```

We will also add the age group and chemo information.

```{r eval=TRUE, message=FALSE}
  # Load the package RCurl
  library(RCurl)
  # Import the RNAseq data set from GitHub; break the string into two for readability
  # (Please note this readability aspect very carefully)
  URL_text_1 <- "https://raw.githubusercontent.com/kannan-kasthuri/kannan-kasthuri.github.io"
  URL_text_2 <- "/master/Workshops/DS_Transcriptomics/Data/marked_data_7000_genes_other_attributes.txt"
  # Paste it to constitute a single URL and import the data
  URL <- paste(URL_text_1,URL_text_2, sep="")
  imported.RNA.seq_other_factors <- read.csv(text=getURL(URL), sep="\t", header = TRUE, stringsAsFactors = FALSE, row.names = 1)
  # Get the Age Group and Chemo status info
  Age_group <- t(imported.RNA.seq_other_factors[2,])
  Chemo_status <- t(imported.RNA.seq_other_factors[3,])
  df.uniq$AGEGROUP <- as.vector(Age_group)
  df.uniq$CHEMO <- as.vector(Chemo_status)
```


Tranformation basics are six key `dplyr` library functions that will allow us to solve vast majority of data manipulation challenges:

1. We can pick observations by their values using the function `filter()`.

2. Reorder the rows applying `arrange()` operation to a data set.

3. We can choose variables by their names using `select()`.

4. Create new variables through `mutate()`.

5. Find the summary using `summarise()` function.

6. And the most important of all which is the `group_by()` operation which can be used with any of the above five.

---

#### The `filter()` function


The filter function allows us to pick a subset of information (or rows) from our dataset.

```{r eval=TRUE, message=FALSE, warning=FALSE, echo=TRUE}
  # Pick all the records of patients with Group = Luminal and FGFR4 value < 5
  filter(df.uniq, Group == 'Luminal', FGFR4 < 5)
```
  
```{r eval=TRUE, message=FALSE, warning=FALSE, echo=TRUE}
  # Pick all the records of patients with AGEGROUP == 41-50 and TP53 value of >= 5
  filter(df.uniq, AGEGROUP == '41-50', TP53 >= 1)
```

**Note**: All `dplyr` functions write the result to a new data frame. If we want to store the data, we need to assign the result to a variable.

We can also use comparison and logical operators. For instance,

```{r eval=TRUE, message=FALSE, warning=FALSE, echo=TRUE}
  # Pick all the records of patients with AGEGROUP == 31-40 and ATM values between 2-4
  filter(df.uniq, ATM >= 2 & ATM <= 4, AGEGROUP == '31-40')
```
  
```{r eval=TRUE, message=FALSE, warning=FALSE, echo=TRUE}
  # Pick all the records of patients who are given Chemo and their TP53 levels >= 2 and ATM levels <= 5
  filter(df.uniq, TP53 >= 2 & ATM <= 5, CHEMO == "Y")
```

will list all the records for patients wwho are given chemotherapy and their TP53 expression levels are greater than $2$ and ATM levels are less than or equal to $5$.

**Note**: `filter()` only includes rows where the condition is TRUE; it excludes both FALSE **and** NA values. 


<br>
<span style="color:blue">**Classwork/Homework**</span>: 

* Find all patients who were not given chemotherapy

1. and have TP53 levels greater than $5$
2. are in age group 41-50 or have luminal type
3. who are in 60+ and are 'Normal-Like'
4. have TP53 levels between 4 and 6
5. have FGFR4 greater than 2
6. have log of STAT3 values greater than 0.2
7. High expression of ATM (more than median) 

* How many patients have a missing ATM value in the df.uniq dataset? 

---

#### The `arrange()` function


`arrange(`) works similar to filter function except that instead of selecting rows, it changes their order. It takes a data frame and a set of column names (or more complicated expressions) to order by. If we provide more than one column name, each additional column will be used to break ties in the values of preceding columns:

```{r eval=TRUE, message=FALSE, warning=FALSE, echo=TRUE}
  # Arrange the data frame arranging Group with descending order of the gene DPM1
  a <- arrange(df.uniq, Group, desc(DPM1))
  atib <- as.tibble(a)
  atib
```
  
For sorting in ascending order we just specify the variable name.

```{r eval=TRUE, message=FALSE, warning=FALSE, echo=TRUE}
  # Arrange the data frame arranging Group with ascending order of the gene FUCA2
  a <- arrange(df.uniq, Group, FUCA2)
  atib <- as.tibble(a)
  atib
```

**Note**: Missing values are always sorted at the end.

To view the last few entries of the data frame/tibble, one can use the `tail()` function.

```{r eval=TRUE, message=FALSE, warning=FALSE, echo=FALSE}
  # Show the last few entries
  tail(atib)
```

<br>
<span style="color:blue">**Classwork/Homework**</span>: 

1. Sort df.uniq to find pateints with high expression in GCLC gene.

2. Sort df.uniq to find patients with highest ATM expression. Do the same to find patients with least ATM expression.

3. For the above question, how do you verify your result?

---

#### The `select()` function

The orginal RNA-seq data set has $6917$ variables/rows. It is common for real world data sets to be large and we may want to quickly zoom into the variables of interest. Also, as the above homework shows, once we arrange the data that has tons of variables, it is difficult to verify the results. The `select()` function allows us to do that. Here is a code to select only the ATM variable:

```{r eval=TRUE, message=FALSE, warning=FALSE, echo=TRUE}
  # Arrange df.uniq to find highest ATM expression
  a <- arrange(df.uniq, Group, desc(ATM))
  # Select only the PID, Group and ATM genes from the above data
  s <- select(a, PID, Group, ATM)
  as.tibble(s)
```

```{r eval=TRUE, message=FALSE, warning=FALSE, echo=TRUE}
  # Select only the PID, Group and TP53 variables
  s <- select(df.uniq, PID, Group, TP53)
  as.tibble(s)
```

An useful helper arument is the `everything()` function that allows keeping all the variables and pushing the variables of interest in the front.


```{r eval=TRUE, message=FALSE, warning=FALSE, echo=TRUE}
  # Push the AGEGROUP and CHEMO variables to the front keeping everything
  s <- select(df.uniq, PID, Group, AGEGROUP, CHEMO, everything())
  as.tibble(s)
```

---

#### The `mutate()` function

We can add new columns to the data set using the `mutate()` function. For example, this code makes a new variable that is the ratio of TP53 and ATM estimate, stores it in a variable "TP53_ATM":

```{r eval=TRUE, message=FALSE, warning=FALSE, echo=TRUE}
   # Select only the variables PID, Group, TP53 and ATM variables
   df_sub <- select(df.uniq,PID,Group,TP53,ATM)
   # Add a new variable TP53_ATM that is a ratio of gene expression in TP53 and ATM
   m <- mutate(df_sub, TP53_ATM = TP53/ATM)
   as.tibble(m)
```


The `transmute()` function retains only the created variables.

```{r eval=TRUE, message=FALSE, warning=FALSE, echo=TRUE}
   # Select only the variables PID, Group, TP53 and ATM variables
   df_sub <- select(df.uniq,PID,Group,TP53,ATM)
   # Add a new variable TP53_ATM that is a ratio of gene expression in TP53 and ATM
   m <- transmute(df_sub, TP53_ATM = TP53/ATM)
   as.tibble(m)
```


There are several useful functions for data manipulation such as `lag()`, `lead()`, `cumsum()`, `min_rank()` etc. and wrappers around them. One of them is the `top_n()` function that is made out of the `filter()` and `min_rank()` functions that would list the top $n$ values from the data. For example, here is a code to select the top $5$ values in the above ratio.

```{r eval=TRUE, message=FALSE, warning=FALSE, echo=TRUE}
  # Select the top 5 ratios in the above transmuted data frame m
  top_5_ratio <-  top_n(m, 5, TP53_ATM)
  top_5_ratio
```

---

#### The `group_by()` and `summarise()` functions

The `group_by()` is an extremely useful function that facililates grouped analysis and along with `summarise()` they can provide vital statistics for a group. Let us say we want to find the mean expression level for TP53 each subtype (Basal, Luminal etc.), the `group_by()` and `summarise()` operation can be extremely handy.

```{r eval=TRUE, message=FALSE, warning=FALSE, echo=TRUE}
  # Group the table by the subgroup 
  df_by_subtype <- group_by(df.uniq, Group)
  # Find the mean cholesterol level for the two GENDERS
  summarise(df_by_subtype, mean_TP53_expression = mean(TP53))
```

We find the mean TP53 expression levels for Claudin-low are little higher than say Luninal subtype.

The `summarise()` has a useful function called the `count()` that will count the number of items appearing in a group. For example, here is an analysis that shows the relationship between FGFR4 and TP53 for each subtype, grouped by the number of patients with the particular subtype.

```{r eval=TRUE, message=FALSE, warning=FALSE, echo=TRUE}
  # First group the patients by age
  df_by_subtype <- group_by(df.uniq, Group)
  # Summarize by counting the number of people in that age, and finding the mean HDL and LDL values
  DL <- summarise(df_by_subtype,
                   count = n(),
                   F = mean(FGFR4),
                   T = mean(TP53))
  
  # We remove the groups with just one person
  DL <- filter(DL,count > 1)
  # Plot this data, with point for count estimates and smoothing it by line
  ggplot(data = DL, mapping = aes(x = F, y = T)) +
    geom_point(aes(size = count, color = DL$Group), alpha = 1) +
    geom_smooth(se = FALSE)
```

We see that several people in Luminal subtype have high FGFR4 and low TP53 levels. 

The big disadvantage in the above code is the necessity to re-type the variables again and again, which can be eliminated through the use of `%>%` symbol. As the analysis becomes complicated, piping becomes extremely useful. The following code is the piped version of the above code producing the exact same output.

```{r eval=FALSE, message=FALSE, warning=FALSE, echo=TRUE}
  # Pipe the expression data to the group_by function, grouping by subtype
  df_by_subtype <- df.uniq %>% group_by(Group) %>%
  # and pipe this to summarize function
  summarise(count = n(),
            F = mean(FGFR4),
            T = mean(TP53)) %>%
  # And pipe this result to filter the count > 1
  filter(count > 1)
  # Plot this data, with point for count estimates and smoothing it by line
  ggplot(data = DL, mapping = aes(x = F, y = T)) +
    geom_point(aes(size = count, color = DL$Group), alpha = 1) +
    geom_smooth(se = FALSE)
```

##### Missing values

The use of the function `na.rm()` inside summarise can be extremely useful as this example shows:

(_Note: Since we already removed 'NA' from our dataset, we import the new data with NA in it_)

```{r eval=TRUE, message=FALSE, warning=FALSE, echo=TRUE}
  # Load the package RCurl
  library(RCurl)
  # Import the HANES data set from GitHub; break the string into two for readability
  # (Please note this readability aspect very carefully)
  URL_text_1 <- "https://raw.githubusercontent.com/kannan-kasthuri/kannan-kasthuri.github.io"
  URL_text_2 <- "/master/Datasets/HANES/NYC_HANES_DIAB.csv"
  # Paste it to constitute a single URL 
  URL <- paste(URL_text_1,URL_text_2, sep="")
  HANES_with_NA <- read.csv(text=getURL(URL))
```

**Without removing NA**

```{r eval=FALSE, message=FALSE, warning=FALSE, echo=TRUE}
  # Group by AGE and GENDER and
  HANES_with_NA %>% 
  group_by(SPAGE,GENDER) %>% 
  # summarize the mean of cholesterol for each group without removing NA
  summarise(mean = mean(CHOLESTEROLTOTAL))
```

```{r eval=TRUE, message=FALSE, warning=FALSE, echo=FALSE}
 # Group by AGE and GENDER and
  HANES_with_NA %>% 
  group_by(SPAGE,GENDER) %>% 
  # summarize the mean of cholesterol for each group without removing NA
  summarise(mean = mean(CHOLESTEROLTOTAL))
```

**Removing NA**

```{r eval=FALSE, message=FALSE, warning=FALSE, echo=TRUE}
  # Group by AGE and GENDER and 
  HANES_with_NA %>% 
  group_by(SPAGE,GENDER) %>% 
  # summarize the mean of cholesterol for each group by removing NA
  summarise(mean = mean(CHOLESTEROLTOTAL, na.rm=TRUE))
```

```{r eval=TRUE, message=FALSE, warning=FALSE, echo=FALSE}
  # Group by AGE and GENDER and 
  HANES_with_NA %>% 
  group_by(SPAGE,GENDER) %>% 
  # summarize the mean of cholesterol for each group by removing NA
  summarise(mean = mean(CHOLESTEROLTOTAL, na.rm=TRUE))
```

We can also filter through the missing values first -

```{r eval=FALSE, message=FALSE, warning=FALSE, echo=TRUE}
  # Filter the data and get no NA values 
  HANES_with_NA %>% filter(!is.na(CHOLESTEROLTOTAL)) %>%
  # group by AGE and GENDER 
  group_by(SPAGE,GENDER) %>% 
  # and find the mean of cholesterol for each group
  summarise(mean = mean(CHOLESTEROLTOTAL, na.rm=TRUE))
```

```{r eval=TRUE, message=FALSE, warning=FALSE, echo=FALSE}
  # Filter the data and get no NA values 
  HANES_with_NA %>% filter(!is.na(CHOLESTEROLTOTAL)) %>%
  # group by AGE and GENDER
  group_by(SPAGE,GENDER) %>% 
  # and find the mean of cholesterol for each group
  summarise(mean = mean(CHOLESTEROLTOTAL, na.rm=TRUE))
```

Whenever we do aggregations using `group_by()` it is good to include count information that will give the information on the distribution and extreme values.

```{r eval=FALSE, message=FALSE, warning=FALSE, echo=TRUE}
  # Group by AGE, GENDER
  cholesterol <- HANES %>% 
  group_by(SPAGE,GENDER) %>%
  # and summarise mean cholesterol
  summarise(mean_cholesterol = mean(CHOLESTEROLTOTAL))

  # We can then plot the count information
  ggplot(data = cholesterol, mapping = aes(x = mean_cholesterol)) + 
  geom_freqpoly(binwidth = 10)
```

```{r eval=TRUE, message=FALSE, warning=FALSE, echo=FALSE}
  # Group by AGE, GENDER
  cholesterol <- HANES %>% 
  group_by(SPAGE,GENDER) %>%
  # and summarise mean cholesterol
  summarise(mg_cholesterol = mean(CHOLESTEROLTOTAL))

  # We can then plot the count information
  ggplot(data = cholesterol, mapping = aes(x = mg_cholesterol)) + 
  geom_freqpoly(binwidth = 10)
```

This reveals that there are patients with extremely high cholesterol ($300$ or more). How does the cholesterol vary over the age group? We can get more insight if we draw a plot of the ratio HDL/LDL and cholesterol for each agegroup:

```{r eval=FALSE, message=FALSE, warning=FALSE, echo=TRUE}
  # For each AGEGROUP find the mean H_L ratio and cholesterol information
  CHO_L_D <- HANES %>% 
  group_by(AGEGROUP) %>% 
  summarise(H_L = mean(HDL) / mean(LDLESTIMATE),
            CHO = mean(CHOLESTEROLTOTAL))

  # Plot this information 
  CHO_L_D %>% 
  ggplot(mapping = aes(x = H_L, y = CHO)) +
  geom_point() + 
  geom_smooth(se = FALSE)
```

```{r eval=TRUE, message=FALSE, warning=FALSE, echo=FALSE}
  # For each AGEGROUP find the mean H_L ratio and cholesterol information
  CHO_L_D <- HANES %>% 
  group_by(AGEGROUP) %>% 
  summarise(H_L = mean(HDL) / mean(LDLESTIMATE),
            CHO = mean(CHOLESTEROLTOTAL))
  
  # Plot this information 
  CHO_L_D %>% 
  ggplot(mapping = aes(x = H_L, y = CHO)) +
  geom_point(mapping = aes(color=AGEGROUP)) + 
  geom_smooth(se = FALSE)
```

This reveals the cholesterol peaks at the age group $40-59$ and remains almost stable, while the age group $20-39$ has the least cholesterol.

There are several useful summary functions:

**Example 1**: Finding the mean of CHOLESTEROLTOTAL and the mean of CHOLESTEROLTOTAL if GLUCOSE >100 for each age group.

```{r eval=FALSE, message=FALSE, warning=FALSE, echo=TRUE}
  DL <- HANES %>% 
    # For each AGEGROUP,
    group_by(AGEGROUP) %>%
    # find the mean of CHOLESTEROLTOTAL and the mean of CHOLESTEROLTOTAL when GLUCOSE content is > 100
    summarise(count = n(),
              H = mean(CHOLESTEROLTOTAL),
              H_glu = mean(CHOLESTEROLTOTAL[GLUCOSE>100])) 
  # And print it
  DL
```

```{r eval=TRUE, message=FALSE, warning=FALSE, echo=FALSE}
  DL <- HANES %>% 
    # For each AGEGROUP,
    group_by(AGEGROUP) %>%
    # find the mean of CHOLESTEROLTOTAL and the mean of CHOLESTEROLTOTAL when GLUCOSE content is > 100
    summarise(count = n(),
              H = mean(CHOLESTEROLTOTAL),
              H_glu = mean(CHOLESTEROLTOTAL[GLUCOSE>100])) 
  # and print it
  DL
```

**Example 2**: Finding the standard deviation of CHOLESTEROLTOTAL by age group

```{r eval=FALSE, message=FALSE, warning=FALSE, echo=TRUE}
  DL <- HANES %>% 
  # For each AGEGROUP,
  group_by(AGEGROUP) %>% 
  # sumamarise the standard deviation of CHOLESTEROLTOTAL and arrange in descending order
  summarise(CHO_sd = sd(CHOLESTEROLTOTAL)) %>% 
            arrange(desc(CHO_sd))
  # and print it
  DL
```

```{r eval=TRUE, message=FALSE, warning=FALSE, echo=FALSE}
  DL <- HANES %>% 
  # For each AGEGROUP,
  group_by(AGEGROUP) %>% 
  # sumamarise the standard deviation of CHOLESTEROLTOTAL and arrange in descending order
  summarise(CHO_sd = sd(CHOLESTEROLTOTAL)) %>% 
            arrange(desc(CHO_sd))
  # and print it
  DL
```

**Example 3**: Finding largest and smallest CHOLESTEROLTOTAL for each diabetes diagnosis group.

```{r eval=FALSE, message=FALSE, warning=FALSE, echo=TRUE}
  DL <- HANES %>% 
  # For each DX_DBTS,
  group_by(DX_DBTS) %>% 
  # find the largest and smallest CHOLESTEROLTOTAL value
  summarise(Lartgest_CHO = max(CHOLESTEROLTOTAL), Smallest_CHO=min(CHOLESTEROLTOTAL)) 
  # and print it
  DL
```

```{r eval=TRUE, message=FALSE, warning=FALSE, echo=FALSE}
  DL <- HANES %>% 
  # For each DX_DBTS,
  group_by(DX_DBTS) %>% 
  # find the largest and smallest CHOLESTEROLTOTAL value
  summarise(Lartgest_CHO = max(CHOLESTEROLTOTAL), Smallest_CHO=min(CHOLESTEROLTOTAL)) 
  # and print it
  DL
```

**Example 4**: Finding largest and smallest CHOLESTEROLTOTAL for each diabetes diagnosis group and by age group.

```{r eval=FALSE, message=FALSE, warning=FALSE, echo=TRUE}
  DL <- HANES %>% 
  # For each DX_DBTS and AGEGROUP,
  group_by(DX_DBTS, AGEGROUP) %>% 
  # find the largest and smallest CHOLESTEROLTOTAL value
  summarise(Lartgest_CHO = max(CHOLESTEROLTOTAL), Smallest_CHO=min(CHOLESTEROLTOTAL)) 
  # and print it
  DL
```

```{r eval=TRUE, message=FALSE, warning=FALSE, echo=FALSE}
  DL <- HANES %>% 
  # For each DX_DBTS and AGEGROUP
  group_by(DX_DBTS, AGEGROUP) %>% 
  # find the largest and smallest CHOLESTEROLTOTAL value
  summarise(Lartgest_CHO = max(CHOLESTEROLTOTAL), Smallest_CHO=min(CHOLESTEROLTOTAL)) 
  # and print it
  DL
```

##### Grouped transformations

Grouping variables is extremely useful when used with the `summarise()` function, but it can also be used with other operations such as `mutate()` and `filter()`. 

**Examples**:

Among the diabetes diagnostic within age groups, find the members (top 3 ranks) with high glucose levels.

```{r eval=FALSE, message=FALSE, warning=FALSE, echo=TRUE}
  # Group by diabetes status and age group,
   HANES %>% group_by(DX_DBTS, AGEGROUP) %>% 
  # filter for the top 3 ranks
   filter(rank(desc(GLUCOSE)) < 3) %>% 
  # select only the relevant variables
  select(DX_DBTS,AGEGROUP,GLUCOSE) %>% 
  # and arrange in descending order of glucose levels
  arrange(desc(GLUCOSE))
```

```{r eval=TRUE, message=FALSE, warning=FALSE, echo=FALSE}
  # Group by diabetes status and age group,
   HANES %>% group_by(DX_DBTS, AGEGROUP) %>% 
  # filter for the top 3 ranks
   filter(rank(desc(GLUCOSE)) < 3) %>% 
  # select only the relevant variables
  select(DX_DBTS,AGEGROUP,GLUCOSE) %>% 
  # and arrange in descending order of glucose levels
  arrange(desc(GLUCOSE))
```

Find age group (not the AGEGROUP variable) greater than a threshold (say, $30$) and standardise A1C to compute per group metric.

```{r eval=FALSE, message=FALSE, warning=FALSE, echo=TRUE}
  # Group by SPAGE and filter groups that contain more than 30 individuals
  AG_GT_30 <- HANES %>% group_by(SPAGE) %>%
                        filter(n() > 30)

  # Filter for all records with A1C variable > 0 to avoid NaNs,
  AG_GT_30 %>% filter(A1C > 0) %>%
  # standardise A1C dividing by the total sum of A1C in the group
  mutate(standardised_A1C = A1C / sum(A1C)) %>%
  # and seelct only A1C and standardised A1C
  select(A1C,standardised_A1C)
```


```{r eval=TRUE, message=FALSE, warning=FALSE, echo=FALSE}
  # Group by SPAGE and filter groups that contain more than 30 individuals
  AG_GT_30 <- HANES %>% group_by(SPAGE) %>%
                        filter(n() > 30)

  # Filter for all records with A1C variable > 0 to avoid NaNs,
  AG_GT_30 %>% filter(A1C > 0) %>%
  # standardise A1C dividing by the total sum of A1C in the group
  mutate(standardised_A1C = A1C / sum(A1C)) %>%
  # and seelct only A1C and standardised A1C
  select(A1C,standardised_A1C)
```

---

#### Selected materials and references

[R for Data Science - Data Transformation Part](https://cran.r-project.org/doc/manuals/R-intro.pdf)

---