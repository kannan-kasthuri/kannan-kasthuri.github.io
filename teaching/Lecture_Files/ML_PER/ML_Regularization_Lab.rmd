---
title: "ML_Regularization_Lab"
author: "Sofia Nomikou"
date: "2/14/2018"
output: html_document
---

# Sampling and Regularization

```{r}
# In case you do not have some of these packages installed, you should run the "install.packages()"command before the library() command the first time you want to run the code. 
  library(RCurl)
  library(tidyverse)
  #install.packages("rafalib")
  library(rafalib)
```

```{r}
# Download data
  URL_text_1 <- "https://raw.githubusercontent.com/kannan-kasthuri/kannan-kasthuri.github.io"
  URL_text_2 <- "/master/Datasets/HANES/NYC_HANES_DIAB.csv"
  URL <- paste(URL_text_1,URL_text_2, sep="")
  HANES <- read.csv(text=getURL(URL))
  HANES$GENDER <- factor(HANES$GENDER, labels=c("M","F"))
  HANES$AGEGROUP <- factor(HANES$AGEGROUP, labels=c("20-39","40-59","60+"))
  HANES$HSQ_1 <- factor(HANES$HSQ_1, labels=c("Excellent","Very Good","Good", "Fair", "Poor"))
  HANES$DX_DBTS <- factor(HANES$DX_DBTS, labels=c("DIAB","DIAB NO_DX","NO DIAB"))
  HANES <- na.omit(HANES)
  str(HANES)
  
  
```


# Sampling Methods

## The validation set approach
```{r}
set.seed(1) # for reproducibility
# Choose the training set as half of the data
train=sample(1112,556)

# Train linear regression only on the train set using the "subset" option
lm.fit = lm(CHOLESTEROLTOTAL~ LDLESTIMATE ,data=HANES,subset=train)

# Predict the MSE on the test set
# you need to run the following command before you run the following one for the first time 
attach(HANES) 

mean((CHOLESTEROLTOTAL-predict(lm.fit,HANES))[-train]^2)

```

```{r}
# What it we choose a different train set?
set.seed(2)
train=sample(1112,556)
lm.fit=lm(CHOLESTEROLTOTAL~ LDLESTIMATE ,data=HANES,subset=train)
#attach(HANES)
mean((CHOLESTEROLTOTAL-predict(lm.fit,HANES))[-train]^2)
```
### It can be observed that with this method, the MSE on the test set is very variable and depends directly on the initial partition of the data in half.

## Leave-One-Out Cross-Validation (LOOCV)
```{r}
library(boot)
#Fit a linear regression model using glm function this time
glm.fit=glm(CHOLESTEROLTOTAL~ LDLESTIMATE ,data=HANES)
# Notice that there is no need to use a train and a test set this time. Why?

# Perform LOOCV 
cv.err=cv.glm(HANES,glm.fit) #might take some time
cv.err$delta # This parameter includes the MSE in this case for LOOCV
```
### The first number is the MSE for the LOOCV and the second is the adjusted value. 

## K-fold Cross-Validation
```{r}
# 10-fold CV
set.seed(17)
cv.error.10=rep(0,10) # create an empty vector to store the error values
for (i in 1:10){ # Try different order polynomials
  glm.fit=glm(CHOLESTEROLTOTAL~ poly(LDLESTIMATE,i) ,data=HANES)
  cv.error.10[i]=cv.glm(HANES,glm.fit,K=10)$delta[1] #extract the MSE error
}
#cv.error.10

plot(seq(1,10,1),cv.error.10, xlab = "Order of polynomial",ylab = "MSE")
```

# Regularization

```{r}
library(glmnet) # Library for regularization

# Make sure you have removed missing values from the data
# We have already done this at the beginning

# Select train and test sets
# Separate our data to train and test set - 90% train, 10% test
index <- sample(1:nrow(HANES),round(0.90*nrow(HANES)))
train <- HANES[index,]
test <- HANES[-index,]
```

## Ridge Regression

```{r}
# Special syntax - matrix x and vector y
train$KEY <- NULL

x=model.matrix(CHOLESTEROLTOTAL~.,train)[,-1] # includes the predictors
y=train$CHOLESTEROLTOTAL # includes the variable we wish to predict

# Set lambda grid to explore all the models
grid=10^seq(10,-2,length=100)
ridge.mod<- glmnet(x, y, alpha=0, lambda = grid) 
# alpha = 0 -> use L2 penalty -> regularization
# family = "binomial" 

dim(coef(ridge.mod))
```
```{r}
# Plot coefficients
plot(ridge.mod, xvar="lambda",main='Ridge')
```

```{r}
set.seed(1)
# Perform cross validation to find the best value of lambda
cv.ridge <- cv.glmnet(x, y, alpha=0,nfolds=10)
plot(cv.ridge)
bestlam=cv.ridge$lambda.min
bestlam

```

```{r}
# Predict MSE on the test set usind the best lambda
test$KEY <- NULL
x.test <- model.matrix(CHOLESTEROLTOTAL~.,test)[,-1] # includes the predictors
y.test <- test$CHOLESTEROLTOTAL

ridge.pred=predict(ridge.mod,s=bestlam,newx=x.test)
mean((ridge.pred-y.test)^2)

```

```{r}
# What if we used not to optimal lambda?
ridge.pred=predict(ridge.mod,s=15,newx=x.test)
mean((ridge.pred-y.test)^2)
```

## Lasso

```{r}
lasso.mod<- glmnet(x, y, alpha=1, lambda = grid) 
# Plot coefficients
plot(lasso.mod, xvar="lambda",main='Lasso')
```
```{r}
set.seed(1)
# Perform cross validation to find the best value of lambda
cv.lasso <- cv.glmnet(x, y, alpha=1,nfolds=10)
plot(cv.lasso)
bestlam=cv.lasso$lambda.min
bestlam
```

```{r}
# Predict MSE on the test set usind the best lambda
lasso.pred=predict(lasso.mod,s=bestlam,newx=x.test)
mean((lasso.pred-y.test)^2)
```

```{r}
# What are the coefficients of the best model?
lasso.coef=predict(lasso.mod,type="coefficients",s=bestlam)[1:20,] 
lasso.coef
lasso.coef[lasso.coef!=0]
```

## In this particular example, if you calculate the mean square error using simple linear regression you will see that the regularization methods did not really improve it. This is because of the particular data we used in this lab, since the number of samples (1001 in train set) is more than enough to accurately predict the coefficients (21 variables) without overfitting the data. In more "real life" applications, regularization methods can really reduce overfitting and improve your method's performance. 









