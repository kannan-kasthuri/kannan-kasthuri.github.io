---
output: html_document
---

<style>
body {
text-align: justify}
</style>

---

### An Introduction to Image Processing (Nov. 06, 2017)

---

We will study some specific ideas in the following general topics in image processing.

- Digital image fundamentals
    - Relationship between pixels
    - Connectivity
- Signal processing background
    - Fourier transforms and its cousins
- Fourier Transform (FT) applications
    - FT applied to primitive images
    - FT applied to real images
- Image sampling 
    - Limits in reconstruction (Whittaker-Shannon Sampling Theorem)
- Image enhancement
    - Various filters
    - Interpolation methods
- Image restoration
    - Noise models
    - Recovering images
- Image segmentation
    - Segmenting by edge detection

---

#### Digital image fundamentals

The term image refers to a 2D light-intensity function denoted by $f(x,y)$, where the value or amplitude of $f$ at spatial coordinates $(x,y)$ gives the intensity (brightness) of the image at that point.

The basic nature of $f(x,y)$ can be characterized by two components:

1. The amount of source light incident (_illumination_) on the scene:

$$
i(x,y) \text{ where } 0\leq i(x,y) \leq \infty
$$

2. The amount of light reflected (_reflectance_) by the objects:

$$
r(x,y) \text{ where } 0\leq r(x,y) \leq 1
$$

Total absorption $r(x,y) = 0$ and $r(x,y) = 1$ is never achieved.

The functions $i(x,y)$ and $r(x,y)$ combine as a product:

$$
f(x,y) = i(x,y)r(x,y) \text{ and hence } 0 \leq f(x,y) \leq \infty
$$

In order for a computer to process an image, it has to be described as a series of numbers, each of finite precision. The digitization of $f(x,y)$ is called:

1. **Image sampling** when it refers to spatial coordinates $(x,y)$ and

2. **Quantisation** when it refers to the amplitude of $f(x,y)$

The images are thus only sampled at a discrete number of locations with a discrete set of brightness levels.

The following is the height profile of Switzerland and sub-sampled height profile of Swiss.

---

![](switzerland.jpg) ![](swiss-sampling.png)

---

Similarly, we can quantize the intensity along the red line:

---

![](swiss-quant.jpg) ![](swiss-cont.png)


---

to get the quantized version,

---

![](swiss-quantized.png)

---

When considered together, the digitization process requires making decision about:

1. the size of the image array $N\times M$ and

2. the number of discrete grey-levels $G$ allowed for each pixel, $f(x,y)$

Thus,

---

![](fxy.png)

---

is an image.

In digital image processing these quantities are usually powers of two, thus,

$N = 2^n$, $M = 2^m$ and $G = 2^k$ for some $n, m \text{ and } k$.

How many samples and grey-levels are required for a good approximation?

1. **Resolution** (degree of discernible detail) of an image depends on the number of samples and grey-levels

2. The bigger these parameters, the closer the digitized array approximates the original image

3. However, the storage and processing time increases rapidly.

---

##### Relationship between the pixels

Quantisation alone does not imply a spatial structure → it must be defined. We have to consider topology and metrics as well. Neighborhood is defined via metrics and vice-versa and are defined on the grid. In 2D they are defined as $4$-, $8$- or mixed-neighborhoods. We will see them now.

But before that we will define the following:

Digital image is denoted by $f(x,y)$, pixels as $p,q$ and subset of pixels of $f(x,y)$ as $S$

**Definitions** 

_$4$-Neighbours_: A pixel $p$ at spatial position $(x,y)$ has $4$ neighbors if $S$ is defined as:

$S:(x+1,y),(x-1,y),(x,y+1),(x,y-1)$

This set of pixels is called the $4$-neighborhood of $p: S=N_4(p)$. Pictorially,

---

![](4-neighbours.png)

---

_Diagonal Neighbours_: The diagonal neighbors of $p$ are $N_D(p)$ is defined as the set $S$:

$S:(x+1,y+1),(x-1,y+1),(x+1,y-1),(x-1,y-1)$

---

![](diagonal-neighbours.png)

---

_8-Neighbourhood_: The set theoretic sum of $N_4(p)$ and $N_8(p)$. 

$S: N_4(p)+N_D(p)\rightarrow N_8(p)$

Thus,

---

![](8-neighbours.png)

---

##### Connectivity

Connectivity between pixels is important in several areas of image processing where we need to identify regions of interest, segment etc. Important to the idea of connectivity is esatblishing boundaries around objects and extract connected components in images.

Two pixels $p,q$ are connected if:

1. They are neighbors, e.g. $N_4(p)$,$N_8(p)$,...

2. Their grey values satisfy a specified criterion of similarity, e.g. in a binary image they have the same value of either $0$ or $1$

Let V be the set of grey-level values used to define connectivity; for example in a binary image $V=\{1\}$ or in a grey-scale image $V=\{16,17,...,32\}$. We can define two types of connectivity:

1. $4$-connectivity if two pixels p,q with values from V and q is in $N_4(p)$

2. $8$-connectivity if two pixels p,q with values from V and q is in $N_8(p)$

---

**$4$-connectivity paradox**

![](4-neighbours-paradoxon.png)

---

**$8$-connectivity paradox**

![](8-conn.prob.png)



**Solution**

Foreground $8$-neighborhood + Background $4$-neighborhood

---

##### Fundamental steps in image processing

---

![](image_processing_steps.png)

---

#### Signal processing background

---

![](FFT1.png)

![](FFT2.png)

---

##### Basic ideas

A periodic function can be represented by the sum of sines and cosines of different frequencies, multiplied by a different coefficient (Fourier Series)

Non-periodic functions can also be represented as the integral of sines/cosines multiplied by a weighting function (Fourier Transformation)

---

##### Fourier transform and its cousins

![](FFT3.png)

---

We will now see an example of a function and its fourier transform. The function is defined by,

$$
f(x) = \begin{cases} A, & \mbox{if } 0 \leq x \leq X \\ 0, & \mbox{otherwise} \end{cases}
$$

---

![](FFT5.png)

---

Why? Because,

$$
\begin{equation} 
\begin{split}
F(u) & = \int_{-\infty}^{\infty}f(x)e^{-j2\pi ux}dx \\
 & = \int_{0}^{X}Ae^{-j2\pi ux}dx \\
 & = \frac{-A}{j2\pi u}\big[e^{-j2\pi ux}\big]_{0}^{X} \\
 & = \frac{-A}{j2\pi u}\big[e^{-j2\pi uX} - 1\big] \\
 & = \frac{A}{\pi u} sin(\pi u X)e^{-j\pi uX}
\end{split}
\end{equation}
$$

---

Discrete Fourier Transform (DFT) is the discrete analog of the fourier transform. Since an image is a two-dimensional quantity, we need DFT in two dimensions. DFT is defined by,

$$
\mathcal{F}\{ f(x,y)\} = F(u,v) = \frac{1}{MN}\sum_{x=0}^{M-1}\sum_{y=0}^{N-1}f(x,y)e^{-j2\pi (ux/M+vy/N)}
$$

for $u = 0,1,2,\dots,M-1$ and $v = 0,1,2,...,N-1$. The _inverse DFT_ is defined by,

$$
\mathcal{F}^{-1}\{ F(u,v)\} = f(x,y) = \sum_{x=0}^{M-1}\sum_{y=0}^{N-1}F(u,v)e^{j2\pi (ux/M+vy/N)}
$$
for $x = 0,1,2,\dots,M-1$ and $y = 0,1,2,...,N-1$.

---

DFT is generally calculated using the Fast Fourier Transform (FFT). FFT is an algorithm to compute DFT in a fast and efficient manner. In general DFT takes about $O(N^2)$. Proper decomposition can reduce the number of multiplications and addition proportional to $O(N\log_2N)$. This decomposition is called the fast Fourier Transform (FFT) algorithm.

For example, let's assume that an FFT of size $8,192$ takes on one particular machine $1$ second. Using the DFT method the same Fourier Transform would require $10$ minutes $30$ seconds.

![](FFT8.png)

---

The dynamic range of Fourier spectra usually is much higher than the typical display device can reliably reproduce. The consequence is that only the brightest parts are shown. A useful technique that compensates for this difficulty is of displaying the following function:

$$
D(u,v) = c. \log[1+\lvert F(u,v) \lvert]
$$
We can see the application of this technique in the following voyager image:

---

![](FFT7.png)

---

#### Fourier transform applications

First we will investigate the "basis" functions for the Fourier Transform (FT). The FT tries to represent all images as a summation of cosine-like images. Therefore images that are pure cosines have particularly simple FTs. Thus we will see FT's application to primitive images.

---

##### FT applied to primitive images

---

![](FTA1.gif)

---

The images are a pure horizontal cosine of 8 cycles and a pure vertical cosine of 32 cycles. Notice that the FT for each just has a single component, represented by 2 bright spots symmetrically placed about the center of the FT image. The center of the image is the origin of the frequency coordinate system. The u-axis runs left to right through the center and represents the horizontal component of frequency. The v-axis runs bottom to top through the center and represents the vertical component of frequency. In both cases there is a dot at the center that represents the (0,0) frequency term or average value of the image. Images usually have a large average value (like 128) and lots of low frequency information so FT images usually have a bright blob of components near the center. Notice that high frequencies in the vertical direction will cause bright dots away from the center in the vertical direction. And that high frequencies in the horizontal direction will cause bright dots away from the center in the horizontal direction.

---

![](FTA2.gif)

---

Here are 2 images of more general Fourier components. They are images of 2D cosines with both horizontal and vertical components. The one on the left has 4 cycles horizontally and 16 cycles vertically. The one on the right has 32 cycles horizontally and 2 cycles vertically. (Note: You see a gray band when the function goes through gray = 128 which happens twice/cycle.) You may begin to notice there is a lot of symmetry. For all REAL (as opposed to IMAGINARY or COMPLEX) images, the FT is symmetrical about the origin so the 1st and 3rd quadrants are the same and the 2nd and 4th quadrants are the same. If the image is symmetrical about the x-axis (as the cosine images are) 4-fold symmetry results.

---

In general, rotation of the image results in equivalent rotation of its FT. To see that this is true, we will take the FT of a simple cosine and also the FT of a rotated version of the same function. The results can be seen by:

![](FTA3.gif)

---

At first, the results seem rather surprising. The horizontal cosine has its normal, very simple FT. But the rotated cosine seems to have an FT that is much more complicated, with strong diagonal components, and also strong "plus sign" shaped horizontal and vertical components. The question is, where did these horizontal and vertical components come from? The answer is that the FT always treats an image as if it were part of a periodically replicated array of identical images extending horizontally and vertically to infinity. And there are strong edge effects between the neighbors of such a periodic array as can be seen by:

![](FTA4.gif)

---

Thus, what we see as the FT in the "slant" image (lower right of the image before last) is actually the combination of the actual FT of the cosine function and that caused by the edge effects of looking at a finite part of the image. These edge effects can be significantly reduced by "windowing" the image with a function that slowly tapers off to a medium gray at the edge. The result can be seen by:

![](FTA5.gif)

---

The windowed image is shown in the upper left. Its FT is shown in the lower left. The non-windowed FT is shown in the upper right and the actual, true FT of a cosine is shown in the lower right. These images are all scaled differently and the comparison is only qualitative, but it can be seen that the windowed image FT is much closer to the true FT and eliminates many of the edge effects.

---

##### FT applied to real images

Now, with the above introduction, the best way to become familiar with Fourier Transforms is to see lots of images and lots of their FTs. First, an interesting pair of images, one sharp and clear, and the other blurred and noisy.

![](FTA6.gif)

---

There are 2 images, goofy and the degraded goofy, with FTs below each. Notice that both suffer from edge effects as evidenced by the strong vertical line through the center. The major effect to notice is that in the transform of the degraded goofy the high frequencies in the horizontal direction have been significantly attenuated. This is due to the fact that the degraded image was formed by smoothing only in the horizontal direction. Also, if you look carefully you can see that the degraded goofy has a slightly larger background noise level at high frequencies. This is difficult to see and perhaps not even meaningful because the images are scaled differently, but if really there, it is due to the random noise added to the degraded goofy. Notice also that it is difficult to make much sense out of the low frequency information. This is typical of real life images.

---

The next images show the effects of edges in images:

![](FTA7.gif)

---

Notice the strong periodic component, especially in the vertical direction for the bricks image. Horizontal components appear closer together in the FT. In the blocks image, notice a bright line going to high frequencies perpendicular to the strong edges in the image. Anytime an image has a strong-contrast, sharp edge the gray values must change very rapidly. It takes lots of high frequency power to follow such an edge so there is usually such a line in its magnitude spectrum.

---

Now lets look at a bunch of different shapes and their FTs.

![](FTA8.gif)

---

Notice that the letters have quite different FTs, especially at the lower frequencies. The FTs also tend to have bright lines that are perpendicular to lines in the original letter. If the letter has circular segments, then so does the FT.

---

Now lets look at some collections of similar objects:

![](FTA9.gif)

---

Notice the concentric ring structure in the FT of the white pellets image. It is due to each individual pellet. That is, if we took the FT of just one pellet, we would still get this pattern. Remember, we are looking only at the magnitude spectrum. The fact that there are many pellets and information about exactly where each one is is contained mostly in the phase. The coffee beans have less symmetry and are more variably colored so they do not show the same ring structure. You may be able to detect a faint "halo" in the coffee FT. What do you think this is from?

---

![](FTA10.gif)

---

Here are our first truly general images. Notice there is very little structure. You can see a top left to bottom right slanting line in the girl image FT. It is probably due to the edge between her hat and her hair. There are also some small edge effects in both images. The mandril image appears to have more high frequency power, probably due to the hair.

---

![](FTA11.gif)

---

The seafan image has a lot of little holes that are about the same size and somewhat randomly oriented. The size of the holes is about 2 pixels wide so that corresponds to frequency components about 1/2 way out to the maximum. The strong horizontal components in the lake image is probably due to the tree trunk edges.

---

Now, here is your first quiz. Consider an image that is totally random. That is, every pixel is some random value, independent of all other pixels. What is its FT?

![](FTA12.png)

---

By the way, notice the single bright dot in the middle of the noise FT image. Why is it there? Why does the noise FT look dark gray?

---

![](FTA13.png)

---

#### Image sampling 

Sampling is the process of measuring the brightness information only at a discrete number of locations. This is modelled as a multiplication with a 1D or 2D pattern (train) of Dirac impulses at these discrete positions.

Consider the real neighbourhood function filtered $f(x)$. Suppose its FT vanishes outside the interval $u\in[-\omega,\omega]$:

---

![](FTA14.png)

---

To obtain a sampled version of $f(x)$ simply involves multiplying it by a sampling function $s(x)$, which consists of a train of Dirac impulses $\Delta x$ apart
Its FT $S(u)$ is also a train of Dirac impulses with a distance inversely proportional to $\Delta x$, namely $1/\Delta x$ apart:

---

![](FTA15.png)

By the convolution theorem multiplication in the image domain is equivalent to convolution in the frequency domain. The transform is periodic, with period $1/\Delta x$, and the individual repetitions of $F(u)$ can overlap → **aliasing**!!! The centre of the overlap occurs at $u=1/(2\Delta x)$

---

![](FTA16.png)

---

To avoid these problems, the sampling interval $\Delta x$ has to be selected so that $1/(2\Delta x)\ge\omega$, or

$$
\Delta x \leq \frac{1}{2 \omega}
$$

---

![](FTA17.png)

---

Once the individual $F(u)$ are separated a multiplication with the window function $G(u)$ yields a completely isolated $F(u)$:

---

![](FTA19.png)

---

The inverse FT then yields the original continuous function $f(x)$. Such a complete recovery of a band-limited function $f(x)$ that satisfies the above inequality is known as the **Whittaker-Shannon Sampling Theorem**.

---

![](FTA18.png)

---

Mathematically, since the fourier transform of a `sinc` function is same as the rectangular function and convolving in the signal domain is same as multiplying in the frequency (fourier) domain, we can write this as:

$$
f(x) = \Big [ \sum_{n=-\infty}^{\infty} f(n) . \delta(x-n\omega) \Big ] * \text{sinc}\Big(\frac{x}{\omega}\Big)
$$

---

##### Example of aliasing

![](FTA20.png)

---

##### Example of good reconstruction

![](FTA21.png)

---

#### Image enhancement

The principal objective of the enhancements techniques is to process the images so that the results are more suitable than the original images for a specific application. The approaches discussed in this chapter fall mainly the categoriy of geometrical image corrections.


---

#### References

1. [Introduction to Signal and Image Processing](https://miac.unibas.ch/SIP/)

2. [Introduction to Fourier Transform for Image Processing](https://www.cs.unm.edu/~brayer/vision/fourier.html)

---