---
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

<style>

body {
text-align: justify;}

figure figcaption {
    text-align: center;}
</style>


---

## Tree-Based Methods/Ensemble Schemes  

---

#### Recorded Stream

---

<iframe width="560" height="315" src="https://www.youtube.com/embed/7Ul5phT8SNM" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>

---

### Classification Trees

---

We will work with HANES data set. Information on HANES can be found [here](http://nychanes.org/). We will first import the curated HANES data set in RStudio:

```{r eval=TRUE, message=FALSE}
  # Load the package RCurl
  library(RCurl)
  # Import the HANES data set from GitHub; break the string into two for readability
  # (Please note this readability aspect very carefully)
  URL_text_1 <- "https://raw.githubusercontent.com/kannan-kasthuri/kannan-kasthuri.github.io"
  URL_text_2 <- "/master/Datasets/HANES/NYC_HANES_DIAB.csv"
  # Paste it to constitute a single URL 
  URL <- paste(URL_text_1,URL_text_2, sep="")
  HANES <- read.csv(text=getURL(URL))
  # Rename the GENDER factor for identification
  HANES$GENDER <- factor(HANES$GENDER, labels=c("M","F"))
  # Rename the AGEGROUP factor for identification
  HANES$AGEGROUP <- factor(HANES$AGEGROUP, labels=c("20-39","40-59","60+"))
  # Rename the HSQ_1 factor for identification
  HANES$HSQ_1 <- factor(HANES$HSQ_1, labels=c("Excellent","Very Good","Good", "Fair", "Poor"))
  # Rename the DX_DBTS as a factor
  HANES$DX_DBTS <- factor(HANES$DX_DBTS, labels=c("DIAB","DIAB NO_DX","NO DIAB"))
  # Omit all NA from the data frame
  HANES <- na.omit(HANES)
  # Observe the structure
  str(HANES)
```

A tibble, or `tbl_df`, is a modern reimagining of the data frame, keeping what has been proven to be effective, and throwing out what is not. To convert a data frame to a tibble, we can use the function `as.tibble(df)` where df is a data frame. We will convert the HANES data frame into tibble and use the tibble from now on.

```{r eval=TRUE, message=FALSE, warning=FALSE}
  # Load the tidyverse library
  library(tidyverse)
  # Convert HANES data frame into a tibble and observe it
  HANES_TIB <- as.tibble(HANES)
  HANES_TIB
```

When we take the logrithm of the variables A1C and UACR, we notice there are two clusters -

```{r eval=TRUE, message=FALSE, warning=FALSE}
  # Make a ggplot for the log(A1C) and log(UACR) variables with asthetic color for the variable DX_DBTS
  ggplot(data = HANES_TIB) + 
    geom_point(mapping = aes(x = log(A1C), y = log(UACR), color=DX_DBTS))
```

These two clusters are primarily composed of non-diabetic people. In the set of all non-diabetic people, if we call the lower cluster (i.e,  `log(UACR) <= -2`) as LOW-UACR and the upper cluster (i.e, `log(UACR) >= -2`) as HIGH-UACR, we would like to construct classification trees to predict these clusters using all variables except UACR. Therefore, we will classify them into these two classes -

```{r eval=TRUE, message=FALSE, warning=FALSE}
  # We can use the mutate function to make this class label and remove non-necessary variables
  mydata <- HANES_TIB %>% filter(DX_DBTS == "NO DIAB") %>% 
    mutate(Cluster = ifelse(log(UACR) <= -2, 'LOW-UACR', 'HIGH-UACR')) %>%
    select(everything(), -KEY, -GENDER, -AGEGROUP, -HSQ_1, -DX_DBTS)
```

The `tree` library can be used to construct classification and regression trees. We can use the `tree()` function to fit a classification tree in order to predict the **Cluster** variable:

```{r eval=TRUE, message=FALSE, warning=FALSE}
  # Load the tree library
  library(tree)
  # We need to convert the Cluster class into factor to use the tree function
  mydata$Cluster <- as.factor(mydata$Cluster)
  # Use the tree function to construct the classification tree removing the UACR and 
  # variables UALBUMIN, UCREATININE that make up UACR
  tree.HANES <-  tree(Cluster~.-UACR-UALBUMIN-UCREATININE, data = mydata)
  # The summary() function lists the variables that are used as internal nodes 
  # in the tree, the number of terminal nodes, and the training error rate
  summary(tree.HANES)
```

We see that the training error is 12%. For classification trees, the reported deviance is given by,

$$ -2 \sum_{m}\sum_{k}n_{mk}\log \hat{p}_{mk}$$

where $n_{mk}$ is the number of observations in the $m$th terminal node that belong to the $k$th class. A small deviance indicates a good fit. The _residual mean deviance_ is simply the deviance divided by $n-|T_{0}|$, which in this case is $977-10$. The `plot()` and `text()` functions can be handy in plotting the tree and viewing it -

```{r eval=TRUE, message=FALSE, warning=FALSE}
  # Plot the tree and label it
  plot(tree.HANES)
  text(tree.HANES, use.n=TRUE, all=TRUE, cex=.6)
```

We should technically use the test error instead of the training error. We will split the observations into a training set and a test set, build the tree using the training set, and evaluate its performance on the test data. The `predict()` function can be used for this purpose. In the case of a classification tree, the argument `type="class"` instructs R to return the actual class prediction. 

```{r eval=TRUE, message=FALSE, warning=FALSE}
  # We will set seed and do a training on 700 data points
  set.seed (2)
  train <- sample(1:nrow(mydata), 700)
  # Form the test data by subtracting the training data indices
  test <- setdiff(seq(1,nrow(mydata)), train)
  # Make HANES test data
  HANES.test <- mydata[test, ]
  # Form the cluster data for tabulating the accuracy
  Cluster.test <- select(mydata, Cluster) 
  Cluster.test <- Cluster.test[test, ]
  Cluster.test <- as.character(t(Cluster.test))
  # Make the tree on the training data 
  tree.mydata <- tree(Cluster~.-UACR-UALBUMIN-UCREATININE, mydata, subset=train)
  # Use predict() function to make a prediction
  tree.pred <- predict(tree.mydata, HANES.test, type="class")
  # Form the accuracy table/confusion matrix
  table(tree.pred,Cluster.test)
```

We see the accuracy is `(227+5)/277 = 83%`.

---

#### Selected materials and references

[R for Data Science - Data Transformation Part](https://cran.r-project.org/doc/manuals/R-intro.pdf)

---